# ğŸ“Š Sales ETL â€“ A Serverless AWS Pipeline

## ğŸ§  Project Goal

This project was built to explore how to implement **cloud-native infrastructure** within an ETL process. 

Up until this point, I had created several ETL pipelinesâ€”but only on my local machine. This project represents a leap into cloud architecture by deploying a secure, serverless ETL pipeline that adheres to **enterprise-grade standards** (e.g., private subnets, scoped IAM roles, and S3 triggers).

> **In short:** A CSV of sales data is uploaded to S3, triggering a Lambda function that transforms and inserts the data into a PostgreSQL database hosted in RDSâ€”all inside a private subnet.

---

## ğŸ› ï¸ Tech Stack

| Tool/Service       | Purpose                                          |
|--------------------|--------------------------------------------------|
| **AWS Lambda**     | Serverless function triggered by S3 upload       |
| **AWS S3**         | Stores CSV files with sales data                 |
| **AWS RDS (PostgreSQL)** | Database to persist sales records          |
| **AWS IAM**        | Scoped role for Lambda S3 access                 |
| **AWS VPC**        | Private subnets, S3 Gateway Endpoints, and route tables |
| **EC2 Bastion Host** | Secure visibility into RDS via port forwarding |
| **Python**         | `boto3`, `pg8000`, `pandas`, `psycopg2`          |
| **DBeaver**        | Local database viewer via SSH tunnel             |

---

## ğŸ“ Folder Structure

```
SalesETL/
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ create_database.py        # Create schema in newly launched RDS
â”‚   â”œâ”€â”€ test_connection.py        # Verifies RDS connection
â”‚   â””â”€â”€ upload_s3_app.py          # Uploads CSV to S3 to trigger Lambda
â”‚
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ __init__.py               # Empty (used for Lambda packaging)
â”‚   â”œâ”€â”€ load.py                   # Handles S3 upload logic
â”‚   â””â”€â”€ transform.py              # Creates table and inserts data into RDS
â”‚
â”œâ”€â”€ lambda/
â”‚   â”œâ”€â”€ lambda_handler.py         # Main Lambda code (runs on trigger)
â”‚   â””â”€â”€ test_lambda_handler.py    # Tests Lambda logic locally
â”‚
â””â”€â”€ data/
    â””â”€â”€ sample_sales.csv          # Example input file
```

---

## ğŸ§ª Sample Data Format

```csv
sale_id,product,quantity,price_per_unit,sale_date
1,Widget A,3,19.99,2025-07-01
2,Widget B,2,24.50,2025-07-01
```

---

## âœ… Features

- âœ… Private subnet for both Lambda and RDS (no public exposure)
- âœ… VPC Endpoint for S3 (no NAT required)
- âœ… Secure IAM roles and scoped permissions
- âœ… Real-time trigger from S3 PUT â†’ Lambda
- âœ… Port-forwarded access to RDS via EC2 Bastion + DBeaver

---

## ğŸ”® Whatâ€™s Next?

Week 5 of the bootcamp may build on this project. If so, Iâ€™ll extend the functionality for:
- Game stats and player rosters (South Broward App)
- Additional Lambda functions
- Streamlit dashboards or RESTful APIs

---

## ğŸ“Œ Notes

- DBeaver requires an SSH tunnel through the EC2 instance to reach the private RDS.
- This project is part learning exercise, part portfolio piece.
- All infrastructure was built manually in the AWS Console for practice and deeper understanding.